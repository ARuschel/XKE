{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "from tools import dataset_tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import config, models\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features from original graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main variables\n",
    "dataset_name               = \"FB13\"\n",
    "embedding_model            = models.TransE\n",
    "model_timestamp            = 'test'\n",
    "neg_rate                   = 2 # negative to positive ratio\n",
    "bern                       = True\n",
    "feature_extractors         = ['pra', 'onesided', 'anyrel'] # pra, onesided or anyrel\n",
    "\n",
    "# GPU settings\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # should be a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './benchmarks/{}/'.format(dataset_name)\n",
    "distribution = 'bern' if bern else 'unif'\n",
    "corrupted_filename = 'train2id_{}negrate_{}.txt'.format(neg_rate, distribution)\n",
    "corrupted_dirpath = dataset_path + '/corrupted/'\n",
    "corrupted_filepath = corrupted_dirpath + corrupted_filename\n",
    "graph_input_dirname = '/pra_graph_input/'\n",
    "pra_graph_input_dir = os.path.abspath(dataset_path + graph_input_dirname)\n",
    "split_name = 'g_{}negrate_{}'.format(neg_rate, distribution)\n",
    "import_path = './results/{}/{}/{}/'.format(\n",
    "    dataset_name,\n",
    "    embedding_model.__name__,\n",
    "    model_timestamp\n",
    ")\n",
    "pra_explain_path = import_path + '/pra_explain/'\n",
    "pra_explain_path_abs = os.path.abspath(import_path + '/pra_explain/')\n",
    "experiment_specs_path = pra_explain_path + '/experiment_specs/'\n",
    "\n",
    "# ensure dirs exist\n",
    "def ensure_dir(d):\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "ensure_dir(pra_explain_path)\n",
    "ensure_dir(experiment_specs_path)\n",
    "\n",
    "# handle feature extraction strings and split name\n",
    "feature_extractor_dict = {\n",
    "    'pra': 'PraFeatureExtractor',\n",
    "    'onesided': 'OneSidedPathAndEndNodeFeatureExtractor',\n",
    "    'anyrel': 'AnyRelFeatureExtractor'\n",
    "}\n",
    "spec_name = split_name + '__'\n",
    "feat_list = []\n",
    "for feat in feature_extractors:\n",
    "    spec_name += '_' + feat\n",
    "    feat_list.append('\"{}\"'.format(feature_extractor_dict[feat]))\n",
    "feat_extractor_string = ','.join(feat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create original graph input for PRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.pra_setup import create_graph_input\n",
    "\n",
    "create_graph_input(\n",
    "    dataset_path,\n",
    "    labels=['valid.txt', 'test.txt'], # folds that have labels\n",
    "    graph_input_dirname=graph_input_dirname\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate/Read Negative Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(corrupted_filepath):\n",
    "    # create corrupted dirpath if not exist\n",
    "    if not os.path.exists(corrupted_dirpath):\n",
    "        os.makedirs(corrupted_dirpath)\n",
    "    # generate corrupted set and save to disk in `corrupted` folder\n",
    "    corrupted = dataset_tools.generate_corrupted_training_examples(dataset_path,\n",
    "            neg_proportion=neg_rate, bern=bern)\n",
    "    train2id = pd.DataFrame(corrupted)\n",
    "    train2id.to_csv(corrupted_filepath,\n",
    "        columns=['head', 'tail', 'relation', 'label'], index=False, header=False, sep=' ')\n",
    "    print('Created corrupted file: {}.'.format(corrupted_filepath))    \n",
    "else:\n",
    "    train2id = pd.read_csv(corrupted_filepath,\n",
    "        names=['head', 'tail', 'relation', 'label'], sep=' ', skiprows=0)\n",
    "    print('Corrupted file already exists: {}.'.format(corrupted_filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read validation and test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid2id_pos = pd.read_csv(dataset_path + 'valid2id.txt', sep=' ', skiprows=1, names=['head', 'tail', 'relation'])\n",
    "valid2id_neg = pd.read_csv(dataset_path + 'valid2id_neg.txt', sep=' ', skiprows=1, names=['head', 'tail', 'relation'])\n",
    "test2id_pos = pd.read_csv(dataset_path + 'test2id.txt', sep=' ', skiprows=1, names=['head', 'tail', 'relation'])\n",
    "test2id_neg = pd.read_csv(dataset_path + 'test2id_neg.txt', sep=' ', skiprows=1, names=['head', 'tail', 'relation'])\n",
    "\n",
    "valid2id_pos['label'] = 1\n",
    "valid2id_neg['label'] = -1\n",
    "test2id_pos['label'] = 1\n",
    "test2id_neg['label'] = -1\n",
    "\n",
    "valid2id = pd.concat((valid2id_pos, valid2id_neg))\n",
    "test2id = pd.concat((test2id_pos, test2id_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train2id.head())\n",
    "display(valid2id.head())\n",
    "display(test2id.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore working model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import train_test\n",
    "con = train_test.restore_model(import_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and Update Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in [train2id, valid2id, test2id]:\n",
    "    fold['label'] = con.classify(fold['head'], fold['tail'], fold['relation'])\n",
    "    fold['label'] = fold['label'].map(lambda x: 1 if x==1 else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode from id to names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity2id, id2entity = dataset_tools.read_name2id_file(dataset_path + 'entity2id.txt')\n",
    "relation2id, id2relation = dataset_tools.read_name2id_file(dataset_path + 'relation2id.txt')\n",
    "n_relations = len(relation2id)\n",
    "\n",
    "for fold in [train2id, valid2id, test2id]:\n",
    "    fold['head'] = fold['head'].map(id2entity)\n",
    "    fold['tail'] = fold['tail'].map(id2entity)\n",
    "    fold['relation'] = fold['relation'].map(id2relation)\n",
    "\n",
    "# WARNING: at this stage we have transformed the dataframes,\n",
    "#   and entities and relations are not represented by ids anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup PRA Experiment Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = \"\"\"\n",
    "{{\n",
    "    \"graph\": {{\n",
    "        \"name\": \"g\",\n",
    "        \"relation sets\": [\n",
    "            {{\n",
    "                \"is kb\": false,\n",
    "                \"relation file\": \"{}/train.tsv\"\n",
    "            }},\n",
    "            {{\n",
    "                \"is kb\": false,\n",
    "                \"relation file\": \"{}/valid.tsv\"\n",
    "            }}\n",
    "        ]\n",
    "    }},\n",
    "    \"split\": \"{}\",\n",
    "    \"operation\": {{\n",
    "        \"type\": \"create matrices\",\n",
    "        \"features\": {{\n",
    "            \"type\": \"subgraphs\",\n",
    "            \"path finder\": {{\n",
    "                \"type\": \"BfsPathFinder\",\n",
    "                \"number of steps\": 2\n",
    "            }},\n",
    "            \"feature extractors\": [\n",
    "                {}\n",
    "            ],\n",
    "            \"feature size\": -1\n",
    "        }}\n",
    "    }},\n",
    "    \"output\": {{ \"output matrices\": true }}\n",
    "}}\n",
    "\n",
    "\"\"\".format(pra_graph_input_dir, pra_graph_input_dir, split_name, feat_extractor_string)\n",
    "spec_fpath = '{}/experiment_specs/{}.json'.format(pra_explain_path, spec_name)\n",
    "with open(spec_fpath, 'w') as f:\n",
    "    f.write(spec)\n",
    "print \"Spec file written: {}\".format(spec_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate split (inside `./results/`) with random negative examples (bernoulli or uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import pra_setup\n",
    "\n",
    "pra_setup.create_split({'train': train2id, 'valid': valid2id, 'test': test2id},\n",
    "                       splits_dirpath=import_path+'/pra_explain/splits',\n",
    "                       split_name=split_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Paths for split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# bash_command = '(cd /home/arthurcgusmao/Projects/xkbc/algorithms/pra/; sbt \"runMain edu.cmu.ml.rtw.pra.experiments.ExperimentRunner {} {}\")'.format(pra_explain_path_abs, spec_name)\n",
    "# for r in relation2id:\n",
    "#     process = subprocess.Popen(bash_command.split(), stdout=subprocess.PIPE)\n",
    "#     output, error = process.communicate()\n",
    "#     print output\n",
    "# print(\"Features (paths) extracted and saved into:\\n{}\".format(os.path.abspath(pra_explain_path)))\n",
    "\n",
    "### not working bro!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$pra_explain_path_abs\" \"$spec_name\" \"$n_relations\"\n",
    "\n",
    "for i in $(seq 1 $3)\n",
    "do\n",
    "    (cd /home/arthurcgusmao/Projects/xkbc/algorithms/pra/; sbt \"runMain edu.cmu.ml.rtw.pra.experiments.ExperimentRunner $1 $2\")\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm /home/arthurcgusmao/Projects/xkbc/algorithms/OpenKE/./results/FB13/TransE/1524490825//pra_explain//results/ -r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
