{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to check whether the training examples for the logits are the same, and to discover why the embedding accuracy for different \"datasets\" is different in the Explanator() output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, time\n",
    "from explain.helpers import parse_feature_matrix, get_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pra_results_dirs = [\n",
    "    \"/home/arthurcgusmao/Projects/xkbc/algorithms/OpenKE/results/WN11/TransE/1527008113/pra_explain/results\",\n",
    "    \"/home/arthurcgusmao/Projects/xkbc/algorithms/OpenKE/results/FB13/TransE/1527033688/pra_explain/results\",\n",
    "    \"/home/arthurcgusmao/Projects/xkbc/algorithms/OpenKE/results/NELL186/TransE/1526711822/pra_explain/results\",\n",
    "]\n",
    "\n",
    "extracted_features_dirs_names = [\n",
    "    \"g_2negrate_bern___pra\",\n",
    "    \"ghat_3nn_2negrate_bern___pra\",\n",
    "    \"ghat_5nn_2negrate_bern___pra\",\n",
    "]\n",
    "\n",
    "def extraction_results(pra_results_dirs, extracted_features_dirs_names):\n",
    "    results = []\n",
    "    \n",
    "    for pra_results_dir in pra_results_dirs:\n",
    "        for extracted_features_dirs_name in extracted_features_dirs_names:\n",
    "            dpath = os.path.join(pra_results_dir, extracted_features_dirs_names)\n",
    "            relations = get_dirs(dpath)\n",
    "            info = {}\n",
    "            \n",
    "            for rel in relations:\n",
    "                for fm in os.listdir(os.path.join(dpath, rel)):\n",
    "                    heads, tails, labels, feat_dicts = parse_feature_matrix(os.path.join(dpath, rel, fm))\n",
    "                    n_feats = pd.Series([len(fd) for fd in feat_dicts])\n",
    "                    info[fm] = info.get(fm, 0) + \n",
    "                    \n",
    "            results.append({\n",
    "                'results_dir': pra_results_dir,\n",
    "                'extracted features': extracted_features_dirs_name,\n",
    "                'total': info.get('train.tsv', 0) + info.get('valid.tsv', 0) + info.get('test.tsv', 0)\n",
    "                'train.tsv': info.get('train.tsv', None)\n",
    "                'valid.tsv': info.get('valid.tsv', None)\n",
    "                'test.tsv': info.get('test.tsv', None)\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"/home/arthurcgusmao/Projects/xkbc/algorithms/OpenKE/results/NELL186/TransE/1526711822/pra_explain/results/g_2negrate_bern___pra/concept:coachwontrophy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path_wn11 = \"/home/arthurcgusmao/Projects/xkbc/algorithms/OpenKE/results/WN11/TransE/1527008113/pra_explain/results\"\n",
    "results_path_fb13 = \"/home/arthurcgusmao/Projects/xkbc/algorithms/OpenKE/results/FB13/TransE/1527033688/pra_explain/results\"\n",
    "results_path_nell = \"/home/arthurcgusmao/Projects/xkbc/algorithms/OpenKE/results/NELL186/TransE/1526711822/pra_explain/results\"\n",
    "\n",
    "results_path = results_path_fb13\n",
    "    \n",
    "features_dir_xke_true = \"g_2negrate_bern___pra\"\n",
    "features_dir_xke_pred_3nn = \"ghat_3nn_2negrate_bern___pra\"\n",
    "features_dir_xke_pred_5nn = \"ghat_5nn_2negrate_bern___pra\"\n",
    "relation = \"gender\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_ent_pairs(results_path, features_dir, fold='train.tsv'):\n",
    "    relations = get_dirs(os.path.join(results_path, features_dir))\n",
    "    ent_pairs_dict = {}\n",
    "    for relation in relations:\n",
    "        rel_features_path = os.path.join(results_path, features_dir, relation)\n",
    "        heads, tails, labels, feat_dicts = parse_feature_matrix(os.path.join(rel_features_path, fold))\n",
    "        ent_pairs_dict[relation] = zip(heads, tails)\n",
    "    return ent_pairs_dict\n",
    "\n",
    "def compare_ent_pairs_dicts_len(d1, d2, d3, names=['d1', 'd2', 'd3']):\n",
    "    res = []\n",
    "    rels = set(d1.keys()).union(set(d2.keys())).union(set(d3.keys()))\n",
    "    lens_sum = [0,0,0]\n",
    "    for rel in rels:\n",
    "        len1 = d1.get(rel, []) # get value with empty list as default\n",
    "        len2 = d2.get(rel, [])\n",
    "        len3 = d3.get(rel, [])\n",
    "        lens = [len(len1), len(len2), len(len3)]\n",
    "        lens_sum = np.sum((lens, lens_sum), axis=0)\n",
    "        res.append(np.concatenate(([rel], lens)))\n",
    "    avg = lens_sum / len(rels)\n",
    "    res.append(np.concatenate((['*SUM*'], lens_sum)))\n",
    "    res.append(np.concatenate((['*AVERAGE*'], avg)))\n",
    "    columns = ['relation']; columns.extend(names)\n",
    "    return pd.DataFrame(res, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_len(results_path, features_dir, fold='train.tsv'):\n",
    "    relations = get_dirs(os.path.join(results_path, features_dir))\n",
    "    features_len_dict = {}\n",
    "    for relation in relations:\n",
    "        rel_features_path = os.path.join(results_path, features_dir, relation)\n",
    "        heads, tails, labels, feat_dicts = parse_feature_matrix(os.path.join(rel_features_path, fold))\n",
    "        min_len=999999\n",
    "        max_len=0\n",
    "        avg_len=0\n",
    "        for fd in feat_dicts:\n",
    "            if len(fd) < min_len: min_len = len(fd)\n",
    "            if len(fd) > max_len: max_len = len(fd)\n",
    "            avg_len += len(fd)\n",
    "        avg_len /= len(feat_dicts)\n",
    "        features_len_dict[relation] = {'min': min_len, 'max': max_len, 'avg': avg_len}\n",
    "    return features_len_dict\n",
    "\n",
    "def compate_features_len():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_examples_directly_from_feature_files(results_path, features_dir, fold='train.tsv'):\n",
    "    \"\"\"The number of examples for each relation.\"\"\"\n",
    "    relations = get_dirs(os.path.join(results_path, features_dir))\n",
    "    examples_count = {}\n",
    "    for rel in relations:\n",
    "        num_lines = 0\n",
    "        with open(os.path.join(results_path, features_dir, rel, fold), 'r') as f:\n",
    "            for line in f:\n",
    "                num_lines += 1\n",
    "        examples_count[rel] = num_lines\n",
    "    return examples_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_number_examples_directly_from_feature_files(results_path, features_dir_xke_true, fold='train.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 'train.tsv'\n",
    "xke_true     = get_list_of_ent_pairs(results_path, features_dir_xke_true,     fold=fold)\n",
    "xke_pred_3nn = get_list_of_ent_pairs(results_path, features_dir_xke_pred_3nn, fold=fold)\n",
    "xke_pred_5nn = get_list_of_ent_pairs(results_path, features_dir_xke_pred_5nn, fold=fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_ent_pairs_dicts_len(xke_true, xke_pred_3nn, xke_pred_5nn, names=['xke_true', 'xke_pred_3nn', 'xke_pred_5nn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_features_path = os.path.join(results_path, features_dir_xke_true, '_similar_to')\n",
    "heads, tails, labels, feat_dicts = parse_feature_matrix(rel_features_path + '/train.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fd in feat_dicts:\n",
    "    print len(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flen_xke_true     = get_features_len(results_path, features_dir_xke_true)\n",
    "flen_xke_pred_3nn = get_set_of_ent_pairs(results_path, features_dir_xke_pred_3nn)\n",
    "flen_xke_pred_5nn = get_set_of_ent_pairs(results_path, features_dir_xke_pred_5nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flen_xke_true     = get_features_len(results_path, features_dir_xke_true, fold='train.tsv')\n",
    "flen_xke_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flen_xke_pred_3nn = get_features_len(results_path, features_dir_xke_pred_3nn, fold='test.tsv')\n",
    "flen_xke_pred_3nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_path = fasdf\n",
    "features_dir = features_dir_xke_true\n",
    "relation = 'cause_of_death'\n",
    "fold = 'train.tsv'\n",
    "\n",
    "heads, tails, labels, feat_dicts = parse_feature_matrix(os.path.join(results_path, features_dir, relation, fold))\n",
    "n_feats = pd.Series([len(fd) for fd in feat_dicts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(n_feats_series.loc[n_feats_series == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(n_feats_series.loc[n_feats_series > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(n_feats_series.loc[n_feats_series > 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(n_feats_series.loc[n_feats_series > 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(n_feats_series.loc[n_feats_series > 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(18, 12)\n",
    "plt.hist(n_feats_series, bins=max(n_feats_series))\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
