{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from explain.pipeline import pipeline, process_overall_metrics\n",
    "from explain.helpers import get_dirs\n",
    "from tools import train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_import_paths = [\n",
    "#     \"/home/arthurcgusmao/Projects/xkbc/algorithms/OpenKE/results/WN11/TransE/1527008113\",\n",
    "    \"/home/arthurcgusmao/Projects/xkbc/algorithms/OpenKE/results/FB13/TransE/1527033688\",\n",
    "    \"/home/arthurcgusmao/Projects/xkbc/algorithms/OpenKE/results/NELL186/TransE/1526711822\",\n",
    "]\n",
    "\n",
    "overalls_output_path = \"~/WHI_overalls.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in emb_import_paths:\n",
    "    pipeline(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dicts = process_overall_metrics(emb_import_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metrics_dicts).to_csv(overalls_output_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run for specific split/relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "from explain.Explanator import Explanator\n",
    "from explain.helpers import ensure_dir\n",
    "\n",
    "##### example without features #####\n",
    "# emb_model_path = \"/home/arthurcgusmao/Projects/xkbc/algorithms/OpenKE/results/NELL186/TransE/1526711822\"\n",
    "# ground_truth_dataset_path = \"/home/arthurcgusmao/Projects/xkbc/algorithms/OpenKE/benchmarks/NELL186/\"\n",
    "# split = \"ghat_3nn_2negrate_bern___pra\"\n",
    "# target_relation = \"concept:visualartistartform\"\n",
    "\n",
    "##### normal example #####\n",
    "emb_model_path = \"/home/arthurcgusmao/Projects/xkbc/algorithms/OpenKE/results/NELL186/TransE/1526711822\"\n",
    "ground_truth_dataset_path = \"/home/arthurcgusmao/Projects/xkbc/algorithms/OpenKE/benchmarks/NELL186/\"\n",
    "split = \"ghat_3nn_2negrate_bern___pra\"\n",
    "target_relation = \"concept:teamalsoknownas\"\n",
    "\n",
    "expl = Explanator(emb_model_path, ground_truth_dataset_path)\n",
    "\n",
    "# variables and ensure dir\n",
    "pra_results_path  = emb_model_path + '/pra_explain/results/'\n",
    "expl_results_path = emb_model_path + '/pra_explain/results_explained/'\n",
    "ensure_dir(expl_results_path)\n",
    "split_path  = os.path.join(pra_results_path,  split)\n",
    "output_path = os.path.join(expl_results_path, split)\n",
    "ensure_dir(output_path)\n",
    "\n",
    "# run functions\n",
    "if expl.load_data(split_path, target_relation):\n",
    "    expl.train_global_logit()\n",
    "    expl.explain_model(output_path=output_path)\n",
    "    # expl.explain_per_example(output_path)\n",
    "    res = expl.get_results()\n",
    "else:\n",
    "    print \"Could not load data.\"\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_test  = expl.test_x.multiply(expl.model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_test.todense()[34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = logits_test.multiply(expl.feature_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(res != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.matrix([[1,2], [0,4]]).multiply([1,2])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl.test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl.test_x.multiply(expl.feature_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_ = np.sum(expl.test_x.multiply(expl.feature_lens)) # sum of all rule lengths for the relation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debug sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = csr_matrix([[0,0,1,1,0,1], [1,1,1,0,0,24]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sm != 0).multiply([0,0,0,0,5,1000]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sm.multiply([0,0,0,1,5,0])\n",
    "res.eliminate_zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(res.getnnz(axis=-1) > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.getnnz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.getnnz(axis=-1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average([1,3,4,5,1,1,1,90,76])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean([1,3,4,5,1,1,1,np.nan,90,76])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl.train_global_logit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from explain.helpers import ensure_dir, get_dirs\n",
    "from explain.Explanator import Explanator\n",
    "import explain.local_functions as lfs\n",
    "\n",
    "\n",
    "def pipeline_debug(emb_model_path, splits=None):\n",
    "    \"\"\"Runs a pipeline for producing explanations with different models for an embedding model.\n",
    "\n",
    "    Arguments:\n",
    "    - `emb_model_path`: (string) path to the embedding model directory.\n",
    "    - `splits`: (list) directory names (inside `/pra_explain/results`) for which the pipeline\n",
    "                       should be run.\n",
    "    \"\"\"\n",
    "    # read model information\n",
    "    model_info = pd.read_csv(emb_model_path + '/model_info.tsv', sep='\\t')\n",
    "    ground_truth_dataset_path = './benchmarks/' + model_info['dataset_name'].iloc[0]\n",
    "\n",
    "    # define directory path variables\n",
    "    pra_results_path  = emb_model_path + '/pra_explain/results/'\n",
    "    expl_results_path = emb_model_path + '/pra_explain/results_explained/'\n",
    "    ensure_dir(expl_results_path)\n",
    "\n",
    "    # get a list of splits (different feature extractions, e.g., using G and G_hat) to run if not provided\n",
    "    if splits == None:\n",
    "        splits = get_dirs(pra_results_path)\n",
    "\n",
    "    # instantiate Explanator for this model\n",
    "    expl = Explanator(emb_model_path, ground_truth_dataset_path)\n",
    "\n",
    "    for split in splits:\n",
    "\n",
    "        split_path  = os.path.join(pra_results_path,  split)\n",
    "        output_path = os.path.join(expl_results_path, split)\n",
    "        ensure_dir(output_path)\n",
    "\n",
    "        target_relations = get_dirs(split_path) # get a list of target relations\n",
    "        results = []\n",
    "\n",
    "        for target_relation in target_relations:\n",
    "            print(\"Loading data for `{}`...\".format(target_relation))\n",
    "\n",
    "            if expl.load_data(split_path, target_relation):\n",
    "\n",
    "                # global logit\n",
    "                expl.train_global_logit()\n",
    "                expl.explain_model(output_path=output_path)\n",
    "                expl.explain_per_example(output_path)\n",
    "                results.append(expl.get_results())\n",
    "\n",
    "                # global regression\n",
    "#                 expl.train_global_regression()\n",
    "                return expl\n",
    "\n",
    "expl = pipeline_debug('./results/WN18/TransE/1526710447')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(expl.train_heads[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl.entity2id['06513953']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl.test_heads[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./benchmarks/WN18/entity2id.txt', sep='\\t', skiprows=1, names=['name', 'id'], dtype={'id': int, 'name': str}, converters={'id': int, 'name': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name'][17071]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2name = {row['id']: row['name'] for _, row in df.iterrows()}\n",
    "name2id = {name: id_ for id_, name in id2name.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2id['06513953']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([2, 405, 999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a > 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = a > 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1 if s else -1 for s in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "d1 = os.path.dirname('./results/FB13/')\n",
    "d2 = os.path.dirname(d1)\n",
    "d3 = os.path.dirname(d2)\n",
    "d4 = os.path.dirname(d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shlex\n",
    "\n",
    "\n",
    "def run_command(command):\n",
    "    process = subprocess.Popen(shlex.split(command), stdout=subprocess.PIPE)\n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if output == '' and process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print output.strip()\n",
    "    rc = process.poll()\n",
    "    return rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_command('(cd /home/arthurcgusmao/Projects/xkbc/algorithms/pra/; sbt \"runMain edu.cmu.ml.rtw.pra.experiments.ExperimentRunner /home/arthurcgusmao/Projects/xkbc/algorithms/OpenKE/results/FB15k/TransE/1526710056/pra_explain/ g2id_2negrate_bern___pra\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tools import generate_g_hat\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "generate_g_hat.run(import_path='./results/WN11/TransE/1527008520', ks=[3,5,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = str(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.split(' -#- ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in s.split(' -#- '):\n",
    "    feat_name, value = feat.split(',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'a': [1,2,3], 'b': [3,4,5]})\n",
    "# df['c'] = [44,99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"augustus_charles_pugin,male\t1\t-children-gender-,1.0 -#- -_parents-gender-,1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_pair, label, features = line.split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line2 = \"augustus_charles_pugin,male\t1\t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_pair, label, features = line2.split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if features:\n",
    "    print 'fasidofjpasod'\n",
    "else:\n",
    "    print 'works.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = zip([1,2,3], [3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3,5) in t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.pra_run import add_triples_without_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_triples_without_features(\n",
    "    '/home/arthurcgusmao/Projects/xkbc/algorithms/OpenKE/results/FB13/TransE/1527033688/pra_explain/results/g_2negrate_bern___pra/',\n",
    "    folds_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1,2,3,97,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"iofajsdpfo\"),\n",
    "print('faiosdoifj crazyyy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test.read_model_info('/home/arthurcgusmao/Projects/xkbc/algorithms/OpenKE/results/FB13/TransE/1527033688/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath('fjaskd/fajsodf/jfaosid/').split(os.sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.zeros((10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([1,1,0,1,1,1,1,1,0,1]) # 70% 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = [{\n",
    "            'l1_ratio': [.1, .5, .7, .9, .95, .99, 1],\n",
    "            'alpha': [0.01, 0.001, 0.0001],\n",
    "            'loss': [\"log\"],\n",
    "            'penalty': [\"elasticnet\"],\n",
    "            'max_iter': [100000],\n",
    "            'tol': [1e-3],\n",
    "            'class_weight': [\"balanced\"],\n",
    "            'n_jobs': [8]\n",
    "        }]\n",
    "gs = GridSearchCV(SGDClassifier(), param_grid)\n",
    "gs.fit(z, y)\n",
    "model = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[0], [1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba([[84]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "clf = DummyClassifier(strategy='prior')\n",
    "x = np.array([2,3,55,23,4345234]).reshape(-1, 1)\n",
    "y = np.array([0,1,0,1,1]).reshape(-1, 1)\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = np.array([5892374,384,0,277,54]).reshape(-1, 1)\n",
    "\n",
    "clf.predict(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([]).reshape(4,0)  # ignored\n",
    "y = [1, -1, 1, 1]\n",
    "clf = DummyClassifier(strategy='prior')\n",
    "clf.fit(X, y)\n",
    "\n",
    "print clf.predict(X)\n",
    "print clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape[:-1] + (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(X.shape[:-1] + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "class PriorClassifier(object):\n",
    "    \"\"\"Returns a dummy classifier that is used when no features are present in training/validation.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.clf = DummyClassifier(strategy='prior')\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(self._adapt_X(X), y)\n",
    "        self.coef_ = np.array([[0]])\n",
    "        proba = self.clf.class_prior_[-1] # get probability of predicting 1, which will be always the same regardless of X\n",
    "        self.intercept_ = math.log(proba/(1-proba)) # apply logit to probability in order to get the intercept\n",
    "\n",
    "    def _adapt_X(self, X):\n",
    "        if X.shape[-1] == 0:\n",
    "            X = np.zeros(X.shape[:-1] + (1,))\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(self._adapt_X(X))\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(self._adapt_X(X))\n",
    "        \n",
    "    def score(self, X, y, sample_weight=None):\n",
    "        return self.clf.score(self._adapt_X(X), y, sample_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([]).reshape(4,0)\n",
    "y = [1, -1, 1, 1]\n",
    "clf2 = PriorClassifier()\n",
    "clf2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2.predict(np.array([[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2.predict_proba(np.array([[1]]))[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = clf2.intercept_; print inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / (1 + math.exp(-inter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.average([1,2,3], weights=[100,100,0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.path.dirname('/here/now/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'/here/now/'.strip('/').split('/')[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
